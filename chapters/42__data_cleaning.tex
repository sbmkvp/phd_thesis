\section{Device fingerprinting}

In the past decade, Wi-Fi has emerged as one of the most commonly used technologies in providing high speed internet access to mobile devices such as smartphones, tablets and laptops in public and private spaces \citep{torrens2008}.
This has resulted in multiple Wi-Fi networks being available at almost every location in dense urban environments.
Traversing through this overlapping mesh of Wi-Fi networks, modern mobile devices with Wi-Fi network interfaces regularly broadcast a special type of signal known as `Probe Requests' in order to discover the Wi-Fi networks available to them.
This helps these devices to connect and switch between the Wi-Fi networks seamlessly.

Probe requests are low level signals standardised by IEEE 802.
1 specification \citep{ieee2016} for service discovery, and are implemented in any Wi-Fi capable device irrespective of the manufacturer or the model.
This ubiquity and standardisation makes them an excellent source of open, passive, continuous, and wireless data generated by Wi-Fi capable devices present at any given time and location.
Considering the unprecedented levels of mobile device ownership in recent years, we can, in turn use this data to understand the population distribution in highly dynamic urban environments with high spatial and temporal granularity \citep{freud2015, konto2017}.
While a Wi-Fi based method to collect data offers us various advantages such as, easy scalability and efficiency in terms of cost and time, it also introduces few systematic biases and uncertainties in the collected data along with the serious risk of infringing on the privacy of the mobile users.
In this section, using the set of probe requests and manual counts collected at various high street locations across London, we demonstrate that pedestrian footfall at these locations can be estimated with considerable precision and accuracy while protecting the privacy of the pedestrians.

Unlike GPS, the location of the Wi-Fi enabled mobile device cannot be directly inferred from Wi-Fi, however there are reliable methods to triangulate the location of mobile devices from the locations of known access points (AP) and the signal strength reported by them \citep{he2003, moore2004, lamarca2005}.
This can overcome the usual shortcoming of GPS, which struggles for precision and accuracy in indoor and densely built environments \citep{zarim2006, kawaguchi2009, xi2010}.
Utilising this, we can easily and quickly estimate trajectories of the mobile devices \citep{musa2012} which can be used similarly to the GPS trajectories to understand individual travel patterns \citep{rekimoto2007, sap2015}, crowd behaviour \citep{abedi2013, mowafi2013}, vehicular \citep{lu2010} and pedestrian movement \citep{xu2013, fukuzaki2014, wang2016}.
Such data can also be used in transportation planning and management to estimate travel time \citep{musa2011} and real time traffic monitoring \citep{abbott2013}.
Using techniques demonstrated by \citep{franklin2006} and \citep{pang2007}, along with information present in the probe requests, one can even model interactions between the users \citep{cheng2012, barbera2013, cunche2014} such as predicting which of them are most likely to meet again \citep{cunche2012}.
Using the semantic information present in these probe requests it even is possible to understand the nature of population at a large scale \citep{di2016}
.

Although extensive research has been carried out on this subject with feasible and favorable results, in recent years, one of the major challenges faced in such attempts has been the increasing attempt by mobile phone manufacturers to protect their users’ privacy by anonymising the globally identifiable portion of the probe requests \citep{greenstein2008}.
Various methods have been devised to overcome this anonymisation process such as estimating the device model information from a known dataset of manufacturers and device behaviours \citep{martin2016}; Scrambler attack using a small part of the physical layer specification for Wi-Fi \citep{vo2016, bloessl2015}; and timing attack where the packet sequence information along with information elements present in the probe request frame is used \citep{matte2016, cheng2016}. A combination of these methodologies has been proven to produce de-anonymised globally unique device information \citep{vanhoef2016, martin2017}. These approaches usually result in serious risk of breach of privacy of the users of the mobile devices by revealing their identifiable personal information.

There is a clear gap in the research for exploring methodologies for estimating the number of unique mobile devices from a set of anonymised probe requests, without the need to reveal their original device information.
Such a technique has various applications such as uncovering the urban wireless landscape \citep{rose2010}, revealing human activity at large scales \citep{qin2013}, estimating pedestrian numbers in crowds \citep{schauer2014, fukuzaki2015}, and even counting people in hyper local scales such as queues \citep{wang2013}.
With enough infrastructure to collect such information we can even aim to generate a real-time census of the city \citep{konto2017}.
With this background, we set out to devise and implement a methodology to reliably estimate human activity such as pedestrian footfall from Wi-Fi probe requests without risking a breach of privacy of the users involved. 

\vspace{1.5em}\noindent\textit{Methodology}\vspace{0.5em}

The primary aim of this research was to enable us to collect a series of probe requests and process them into a usable pedestrian footfall count.
We did this by using a Wi-Fi receiver to collect probe requests broadcast by mobile devices, filtering out the background noise, and aggregating them based on the device that generated them.
In this section, we examine the characteristics of probe requests in detail, devise a methodology to collect these probe requests in public areas, examine the systemic biases and uncertainties in the data collection method, and devise data processing methods to overcome these challenges.
Finally, we compare the processed footfall counts to the ground truth recorded by primary surveys.

Probe requests are a special type of management packet broadcast by Wi-Fi enabled devices as part of their various functions such as scanning for available APs and quick geolocation by triangulation based known APs, etc.
These are broadcast by all Wi-Fi enabled devices regardless of the manufacturer, type or model of the devices, although there is some variation in the frequency and the content of the information transmitted through them.
In some cases, such as Android devices, these are broadcast even when the Wi-Fi functionality has been turned off by the user so that the device can immediately connect to networks when the functionality is switched back on.
Since some devices even use the probe requests as a less accurate form of localisation, they continuously send probe requests when Wi-Fi has been switched off.
Thus, these signals can be used to reliably identify the presence of Wi-Fi enabled mobile devices.
Being a first step of connection initiated by the mobile device, these packets have information regarding the characteristics of the mobile device itself.
Some of the key information we can infer from these requests are,

\begin{enumerate} 
\item \textbf{Media Access Control (MAC) address} which is a name identifying the wireless hardware of the mobile device, 
\item \textbf{Sequence number} of the request for the mobile device to keep track of the responses, 
\item \textbf{Time stamp} at which the request was received by the AP, 
\item Total \textbf{length} of the request in number of bits, and 
\item The \textbf{strength of the signal} received by the mobile device.
\end{enumerate}

The MAC address is the primary identifier for the mobile device and has two parts.
The first part is the Organisationally Unique Identifier (OUI) which provides information about the manufacturer of the device and the second part is the identifier for the device.
In modern devices, to protect users' privacy, the second part of the MAC address can also be randomised and hence may not be unique to devices.
When the MAC address is randomised, it is marked as such by setting a specific bit in the probe request packet as 1.
Although sequence number of the packet is strictly unique to a mobile device, we hypothesize that we can use them to estimate the number of unique devices as demonstrated by \citep{vanhoef2016}; where optional information present in the probe requests - Information Elements (IE) along with the sequence numbers, have been used to fingerprint the devices.
This approach has become increasingly difficult as mobile phone manufacturers have severely limited the IEs present in the probe requests thus leading us to explore methods which use only the sequence numbers.
This also affects the established commercial solutions using Wi-Fi probe requests such as Blix, Walkbase, Euclid Analytics, RetailNext etc.
There has been another solution proposed by \citep{hong2018} where the authors tried to solve the similar problem using a hidden markov models based trajectory inference algorithm but the scope of this research was limited to enclosed, exit controlled public spaces such as shopping malls, railway stations, etc.

Data collection was done with the help of custom sensors built from modifying the hardware used in Smart Street Sensors \citep{sss2016} and updating them with custom software.
The sensor is essentially a Raspberry-Pi device with Wi-Fi and 3G modules.
It keeps the Wi-Fi module in `Monitor mode' and uses the open source software - Wireshark \citep{wireshark2} to passively collect all packets sent to `broadcast', marked with type as `management', and subtype `probe requests'.
The MAC address in these probe requests is obfuscated at the device level using a cryptographic hashing algorithm and transmitted through 3G connection to a central database via web-sockets protocol, where it is stored in a PostgreSQL database for further analysis.
The random salt used in the hashing algorithm was rotated regularly to further mitigate the risk of de-anonymisation of the hash.
Though hashing cannot completely ensure anonymisation as discussed in \citep{demir2014}, it can sufficiently obfuscate the data; which along with a secure process of data handling, gives us reasonable security.
An overall schematic of the data collection and storage process is shown in Figure \ref{datacollection_schematic}.
The ground truth on the number of pedestrian footfall was recorded using a custom Android application - Clicker \citep{bala2018}.
This app logs accurate timestamps each time the surveyor records a pedestrian crossing the designated cordon line at the location.
In addition to counting the pedestrians manually, this procedure results in the device broadcasting probe requests regularly, which in turn, gives us a `known device' to calibrate our methodology against.


% \begin{figure} 
% 	\centering \includegraphics[width=\linewidth]
% 		{images/figure_1.jpeg}
% 	\caption 
% 		{Schematic diagram showing the process of collecting and storing probe
% 		requests using the sensor}
% 	\label{datacollection_schematic} 
% \end{figure}

After collecting data, we began estimating the footfall or pedestrian activity from them by identifying the following potential uncertainties arising from our data collection method:

\begin{enumerate} 
  \item \textbf{Background noise} - since the extent to which Wi-Fi signals travel differs subject to various factors such as interference and humidity, it is close to impossible to restrict our data collection to a finite area of interest.
  This can lead to a significant background noise at certain locations.
  For example, a phone shop or a bus stop located next to the study area can artificially increase the number of probe requests received by the sensor.
  It is important to note that this method may not work effectively on study locations with complex configurations such as the source of noise and the area of study being located at the same distance from the sensor.
  This aspect is explored in detail in the broader case study in the following sections.
  \item \textbf{MAC randomisation} - mobile devices in recent years have been using randomised `local' MAC addresses for probe requests to protect the users from being tracked.
  This makes it impossible to tell if the probe requests are being sent by the same mobile device. This along with the previous problem can further increase the magnitude of error by several fold.
  \item \textbf{Mobile ownership} - since the rate of mobile ownership can vary widely across geography and demography, we cannot assume that every mobile device translates to one pedestrian footfall.
  In addition to this, there is a long term overall increase in mobile ownership which may affect the number of probe requests collected overtime.
\end{enumerate}

We propose the following internal and external validation methods to tackle each of these uncertainties.

% \begin{figure} 
% \centering 
% \subfigure [Distribution of signal strengths (dBm) showing the filtering of
% 		background noise] {\resizebox*{0.45\linewidth}{!}
% 		{\includegraphics{images/figure_2a.jpeg}}}
% \hspace{20pt}
% \subfigure [Clustering probe requests as nodes in a graph using increasing
% 		sequence numbers] {\resizebox*{0.45\linewidth}{!}
% 		{\includegraphics{images/figure_2b.jpeg}}}
% \caption {Schematic diagrams explaining the methods for filtering by signal
% 	strength and clustering using sequence numbers}
% \label{methodology_schematic}
% \end{figure}

\vspace{1.5em}\noindent\textit{Filtering with Signal Strength}\vspace{0.5em}

One of the clues that we can use to estimate the distance between the mobile device and the sensor is the strength of the signal received by the sensor.
The obvious approach was to first try and establish a relationship between the signal strength and distance and to use this to filter out the unwanted probe requests.
However this approach was found to not be feasible, since the decay of signal strength with respect to distance is not always constant.
For instance, signal strength varies with atmospheric conditions, the presence of obstructions between the source and the target, the nature of these obstructions, and the strength (power level) of the source.
This severely limits our ability to establish a simple conversion between reported signal strength and distance.
As such, there was a need for a method which takes in to account all of these variables across the various locations.

We assumed that, in configurations where a specific source of background noise was at a constant distance, there must be a distinct pattern in the number of probe requests reporting signal strength corresponding to that distance.
For example, if there was a phone shop next to our sensor where hundreds of phones regularly sent probe requests, there should be a sharp rise in the of number of probe requests with reported signal strength corresponding to the distance between the sensor and the phone shop, irrespective of the local conditions as shown in Figure \ref{methodology_schematic}.
We could identify these breaks in the data using traditional one dimensional clustering algorithms such as `jenks natural breaks', `k-means', `quantile' and `hierarchical clustering', etc.
Since we were only looking for the break in the data and not for absolute values, the methodology should apply for all the variations due to micro site conditions reducing the overall noise in the collected data.

\vspace{1.5em}\noindent\textit{Clustering with sequence numbers}\vspace{0.5em}

Since our primary unique identifier - MAC addresses are being anonymised by new devices, we needed to find other information present in the probe requests for use as a unique identifier.
The obvious approach was to establish a factor of randomisation, and adjust the counts for the probe requests based on this factor.
We found this approach to not be feasible since the proportion of devices which randomise the MAC addresses increased over time.
There was also a wide variation in the frequency at which the devices randomised the MAC addresses and the method used for the process.
This led us to look for a more generalisable approach which was independent of the device model.
From our initial look at the data, we found that OUI and the sequence number of the packet was the most promising information to achieve this.
First we divided our dataset into sets of probe requests with randomised and non-randomised MAC addresses by looking at the second character of the vendor part of the MAC address; if it was E, A, 2 or 6, then those addresses were identified to be randomised.
We kept the MAC address as the unique identifier for the non-randomised requests and further divided the randomised ones in to sub-categories based on their OUI.
We then  identified unique mobile devices from within those sets, and assigned a unique identifier to each device.

The proposed algorithm created a graph where the probe requests represented the nodes; links were created between them based on the following rules:

\begin{itemize} 
  \item A link could go only forward in time.
  \item A link could go from low to high sequence numbers. 
  \item A link could exist between nodes with a maximum time difference of $\alpha$ - time threshold.
  \item A link could exist between nodes with a maximum sequence number difference of $\beta$ - sequence threshold.
  \item A node could have only one incoming link and one outgoing link, which is the shortest of all such possible links in terms of both time and sequence number.
\end{itemize}

The nodes were then assigned a unique ID based on the unique connected component they belonged to as shown in Figure \ref{methodology_schematic}.
This unique identifier was used in the place of MAC addresses for aggregation of the anonymised probe requests.
Although the recycling of sequence numbers after 4096 led to multiple unique IDs being reported from a single device, a sample consisting of all randomised probe requests sent by "Google" devices showed that only 0.
\% of the sample had their sequence number reset.
This led assume this to be inconsequential.

\vspace{1.5em}\noindent\textit{Calibrating with Ground Truth}\vspace{0.5em}

Since proportions of mobile device ownership was an external uncertainty to our study and could arise from variety of spatio - temporal and demographic factors, we aimed to solve this by using a manual sample count at each location.
We then calculated an adjustment factor, or an `offset' for each location by comparing the sensor-based counts and ground truth.
In turn it was then used to adjust the data reliably to reflect the ground truth in absolute numbers.
This calibration can be carried out periodically at these locations to improve the quality of the estimation.


\subsection{pilot study}

\begin{table}
\caption{Comparison of clustering algorithms with a sample of 40000 probe requests}
{\begin{tabular}{lcc} 
	\toprule
	 Algorithm					& Time (s) 	& MAPE (\%) \\
	\midrule
	 Quantile					& 0.002 	&  27 \% \\
	 K-Means			 		& 0.007 	& -23 \% \\
	 Hierarchical Clustering	& 172.520 	&  -9 \% \\
	 Bagged Clustering 			& 0.135 	& -30 \% \\
	 Fisher 					& 3.034 	& -30 \% \\
	 Jenks Natural Break 		& 556.279 	& -30 \% \\
	 \bottomrule
\end{tabular}}
\label{classification-table}
\end{table}

To start, we designed a small pilot study to validate the filtering and clustering methodology against the scale and complexity of data collected in an open public area such as a retail high street.
We also aimed to find the algorithm which was best suited for the classification of signal strengths as 'low' and 'high' in order to filter out the background noise.
The data was collected at Oxford Street, London on 20 December 2017 from 12:30 to 13:00 hrs, Wi-Fi probe requests were collected using the sensor described in Section \ref{methodology} and pedestrian footfall was manually recorded using the Android app - Clicker \citep{bala2018}.
Being located at one of the busiest retail locations in the United Kingdom, the Wi-Fi sensor captured approximately 60,000 probe requests during the half hour period; 3,722 people were manually recorded walking on the pavement during that time.
The surveyor positioned himself at the front of a store while carrying the sensor in a backpack and counted people walking by the store on the pavement (3m wide approximately) using a mobile phone.
The sensor was kept as close to the store window as possible, and the manual count was done as a cordon count in front of the store.

As a first step we aggregated the probe requests by their MAC addresses for every minute to generate a minute by minute count of the number of people near the sensor.
We assumed that each MAC address corresponded to a mobile device and hence a pedestrian.
We then compared this preliminary `footfall' count to the actual number of pedestrians recorded manually to check for it's robustness.
We used Mean Absolute Percentage Error (MAPE) as a measure of robustness of the count, since it provided a simple and quick measurement and the street conditions ensured that there are no intervals without any footfall.
We found that the MAPE in the raw counts compared to the ground truth was around 425\%.
 This suggests the presence of large amount of noise in the data which may have been generated by the sources of uncertainties discussed in Section \ref{methodology} thus demonstrating the need for filtering the data.

We then classified the probe requests as `high signal strength' and `low signal strength' using various one dimensional clustering algorithms such as k-means, quantile, hierarchical clustering, bagged clustering, fisher and jenks natural breaks with the number of clusters set as 2.
The results are shown in Table \ref{classification-table}.
We found that while hierarchical clustering and jenks gave us fairly low errors, they were too resource intensive for practical use with a larger dataset.
We also found that k-means gave the quickest results with the lowest MAPE, closely followed by quantile algorithm.
The cut-off point or threshold for the collected data with which we could classify as high and low was -71 dBm.
We then removed all the probe requests which reported `low signal strength' and repeated the same aggregation process as before to produce footfall count.
This process resulted in a footfall count with a net MAPE of 30\%.
Although the results are encouraging we are still not completely confident that our filtering process is removing noise or has any correlation the configuration of sensor or position of the mobile devices.
These concerns need to be addressed with a larger survey with multiple locations of varying orientations.

% \begin{figure}
% \begin{center}
% \includegraphics [width=\linewidth,trim=1 1.5 1 1.5,clip]
%     {images/figure_3.jpeg}
% \caption{The clustering process was repeated with both increasing sequence
%     number threshold ($\alpha$) and time threshold ($\beta$), until we arrived
%     at the lowest parameters where the know device (black line) is clustered as
%     a single device.}
% \label{pilot_clustering_params}
% \end{center}
% \end{figure}
%
% \begin{figure}
% \centering
% \subfigure[Clustering probe requests based on increasing sequence numbers 
% 	present in them.]
% 	{\resizebox*{0.475\linewidth}{!}
% 	{\includegraphics{images/figure_4a.jpeg}}}
% \hspace{20pt}
% \subfigure[Comparison of sensor based counts with the ground truth.]
% 	{\resizebox*{0.45\linewidth}{!}
% 	{\includegraphics{images/figure_4b.jpeg}}}
% \caption{The results of the pilot study demonstrating the validity of the
% 	methodology.} 
% \label{pilot_results}
% \end{figure}

The next challenge was to identify the probe requests which are generated by the same device irrespective of the MAC randomisation process.
We used the algorithm defined in Section \ref{methodology} and assigned a unique identifier or signature to each probe request, independent of their the MAC addresses.
 Since we didn't know the nature or frequency of the MAC address randomisation process, we used the surveyor's mobile device as a reference.
As the surveyor's device was being actively used to count pedestrians and it's Wi-Fi module was kept active without establishing connection to any network, the device was known to be continuously probing for new networks.
We also knew that the OUI of the device was 'Google' and the device was regularly randomising it's MAC address, thus providing us an excellent reference with which we could optimise the parameters for our clustering algorithm.
We then, by increasing the thresholds in steps of 1, found the minimum possible threshold for time and sequence numbers at which the algorithm clusters the reference device properly without over clustering the other probe requests.
 This process is shown in Figure \ref{pilot_clustering_params}.
We observed that the threshold for time $\alpha$ and the threshold for sequence numbers, $\beta$ are 16 seconds and 60 respectively This was undertaken on top the filtering done based on signal strength, and only for the probe requests with randomised MAC addresses.
Figure \ref{pilot_results} shows the results of this clustering process on a small set of randomised probe requests.
The probe requests with different randomised MAC address are shown by the coloured points and the lines joining them show that those probe requests were most likely be generated by the same device.
We finally aggregated the probe requests as we did before but with the device signature rather than MAC addresses.
This results in a footfall count with a MAPE of -18\% compared to the manual count.
A comparison of minute by minute counts resulting from different filtering processes along with the ground truth is shown in Figure \ref{pilot_results} illustrating the promising effectiveness of the methods.

To conclude, from the pilot study we found that both the filtering and the clustering methods we devised worked on complex real world data and resulted in final pedestrian counts within a MAPE of 20\%.
We also found that `k-means' and `quantile' are best algorithms for clustering signal strengths.
Finally, we observed that the best thresholds for time and sequence numbers in the clustering algorithm is around 16 and 60 respectively.

\subsection{main study}

The methodology set out above was implemented in five different Central London locations at different times. Sensors were installed and data collected for extended periods of time. We also carried out manual counting at these locations across different times of the day. We then applied the methodologies discussed earlier to arrive at estimated pedestrian footfall and compared them with the corresponding manual counts.  We finally evaluated the effectiveness of the processes with the Mean Absolute Percentage Error (MAPE) at the locations and report our findings below.  

\begin{table}
    \caption{Locations where sensors were installs, volume and speed of probe requests collected by
    the sendor and total pedestrians manually counted. The data occupies around 1.8 GB on disk 
    when encoded in text format.}
    {\begin{tabular}{cp{2cm}p{1.5cm}p{2cm}cc} 
		\toprule
         ID & Location & Type & Installation notes & Probe Requests & Footfall\\
         % & & & & x10\textsuperscript{6} (per min) & No. (per min)\\
		 \midrule
         1 & Camden High Street & Phone Shop & Bus stop in front & 9.9 (297) & 3683 (33)\\
         2 & Central St.Giles & Restaurant & Seating area on both sides & 3.9 (169) & 0346 (05)\\
         3 & Holborn Station & Info. Kiosk & Overlooks station entrance & 4.3 (303) & 2956 (46)\\
         4 & Brunswick Center & Fast Food & Has seating area on one side & 3.4 (210) & 0960 (12)\\
         5 & The Strand & Tea Shop & Has phone shop next door & 8.4 (382) & 1969 (21)\\
		 \bottomrule
	\end{tabular}}
	\label{locations-table}
\end{table}

% \begin{figure}
% 	\begin{center}
% 		\includegraphics [width=0.90\linewidth] {images/figure_5.jpeg}
% 		\caption{Data collection schedule showing the days when sensors were active at their corresponding locations. The red squares show that manual counting of pedestrians was also done on that day.}
% 		\label{main_schedule}
% 	\end{center}
% \end{figure}

The locations at which the data were collected are shown in Table
\ref{locations-table}. The locations were chosen for their diverse site
conditions and unique sources of noise around the potential location of the
sensors. The position of the sensor at these locations with respect to the
context is shown the Figure \ref{main_signal_strength}. We can see that
Location 5 is the `cleanest' with one clear stationary source of noise (phone
shop) while location 2 is the most complex due to the proximity of seating
areas to the sensor.  The sensors were operational through out February and
March, while manual counts were conducted in these locations in half hour
sessions on at least two different days. For the purposes of comparing with
ground truth, we considered the data from sensors which correspond to the 12
sets of available manual counts. The schedule of data collection is shown in
Figure \ref{main_schedule}.

% \begin{figure}
% 	\centering
% 	\subfigure[Installation configuration of sensors at the survey locations (not to scale)]{
% 		\resizebox*{0.46\linewidth}{!}{\includegraphics[trim=2 6 2 6,clip]{images/figure_6a.jpeg}}}\hspace{20pt}
% 	\subfigure[Density distribution of signal strength reported in collected probe requests (lower values show higher signal strength)]{
% 		\resizebox*{0.46\linewidth}{!}{\includegraphics[trim=2 4 2.5 6,clip]{images/figure_6b.jpeg}}}
% 	\caption{Distribution of signal strengths across locations} \label{main_signal_strength}
% \end{figure}

We begin by looking at the distribution of the signal strength reported by the
probe requests across the locations. From the density plot shown in Figure
\ref{main_signal_strength}, we can observe that there is clear relation between
the distribution of the signal strength and the distance and complexity of the
source of noise. We can see that while location 5 shows clean difference
between low and high signal strengths, location 2 is almost normally
distributed.  Intuitively we expected that location 2 and 4 would be harder to
classify than locations 1, 3 and 5.  We ran the k-means clustering algorithm
and filtered out the probe requests which were randomised and had signal
strengths less than the second break (threshold).  It is important to note that
we were dealing with relative thresholds of signal strengths which can vary
with location and time of the analysis.  We then aggregated the probe requests
by counting the number of Unique MAC addresses present in every minute. We also
removed devices that dwelled around the sensor by removing the MAC
addresses which reappeared within the previous hour.

The results of the first stage of the filtering process along with the
thresholds are shown in Table \ref{errors_table}.  Confirming our intuition, we
see that the location 2 has the most MAPE followed by location 4, while the rest
of them have highly reduced MAPE.  It is significant that this method alone
reduces our margin of error by 50 - 100\% from the raw counts without any
cleaning.  This makes the signal strength filtering a quick and ideal method for
practical applications, one which doesn't require absolute numbers such as
creating large aggregated indexes to show long-term trends.  We also found that
the success of the signal strength filtering can be improved significantly by
installing sensors so that the pedestrians and source of noise are at different
distances from the sensor. This ensures that the distribution of signal
strengths within the field of measurement is distinct from that of the
surroundings.

We then ran the sequence numbers based clustering process on the rest of the
probe requests to reduce the MAPE by almost 50 - 100\% on all the sensors except
for location 3.  Location 3 is an outlier among all the other sensors since it
is the only one with large amount of pedestrians very close to the sensor.  This
may be the reason behind the over filtering observed in the previous process.
We finally ran the calibration process where we calculated the adjustment
factors from the ratio between the manual counts to the sensor based counts for
the sample period as shown in Table \ref{errors_table}.  We used them to adjust
the counts to achieve a MAPE ranging from 10 - 50\%. We observed that the
sensors with people moving right next to them tend to under-count with our
methodology, while sensors with seating next to them tend to over-count
significantly. However, using the filtering process, we can reduce the error to
almost 10\% closer to that of the ground truth.

\begin{table}
  \footnotesize
	\caption{Results of footfall estimation at each location as Mean Absolute Percentage Error (MAPE) after each step of the filtering process}
  {\begin{tabular}{cp{1.4cm}p{1.4cm}p{1.4cm}p{1.4cm}p{1.4cm}p{1.4cm}} 
		\toprule
			Sensor & Signal strength threshold& Adjustment factor& MAPE without any & MAPE after filtering signal& MAPE after filtering sequence & MAPE of final adjusted\\
			&  &  & &  &  & \\
			% & (-dBm) & &  cleaning (\%) & strength (\%) & numbers (\%) & counts (\%)\\
		 \midrule
			1 & -70 & 1.25 & 259 &  22 & -13 &  9 \\
			2 & -74 & 0.51 & 928 & 396 & 206 & 55 \\
			3 & -72 & 1.60 &  87 & -19 & -31 & 10 \\
			4 & -70 & 0.88 & 498 & 142 &  52 & 33 \\
			5 & -72 & 0.80 & 473 &  84 &  38 & 11 \\
		 \bottomrule
	\end{tabular}}
	\label{errors_table}
\end{table}

% \begin{figure}
% 	\begin{center}
% 		\includegraphics [width=\linewidth,trim=6 6 6 6,clip] {images/figure_7.jpeg}
% 		\caption{Comparison of the filtering process with the ground truth in all the locations.}
% 		\label{main_comparison}
% 	\end{center}
% \end{figure}
%
% \begin{figure}
% 	\begin{center}
% 		\includegraphics [width=\linewidth] {images/figure_8.jpeg}
% 		\caption{A week of pedestrian footfall at the Strand, London collected by the methodology. The counts are aggregated for 5 minute intervals.}
% 		\label{main_study_counts}
% 	\end{center}
% \end{figure}

\subsection{Conclusions}

Sentient technologies make measurement of the human activities that are the life blood of the smart city possible.
Yet the data that they harvest are frequently relevant only to the sub-groups within society that avail themselves of particular goods and services – such as social media applications, transport modes or retail offers.
In each of these cases, it is necessary to remember that the resulting data are by-products of consumer transactions, and will as a consequence, only pertain to users of the relevant goods or services.
If the smart city is to be socially inclusive, it therefore follows that sentient data must represent entire populations, whether by design or by triangulation with external, population wide, sources.
This is a non-trivial task, since the ebbs and flows of smart device-enabled citizens rarely pertain to any clearly defined population in either administrative or functional terms \citep{massam1975}.

Our objective here has been to collect, rather than re-use, data on smart city functioning, by recording Wi-Fi probes and ultimately reconciling them with manual counts in order to infer ambient populations.
The internal validation methodology set out in the technical sections of this paper, allied to external validation from pedestrian counts, renders the method inclusive and robust when recording activity levels in retail centres in real time.
We have described the collection and processing of a novel consumer Big Dataset that enables valid measures of levels of footfall activity which has been scaled across a wide network of sensors \citep{cdrc2018}.
 In both conceptual and technical terms, it illustrates the ways in which passively collected consumer data can be ‘hardened’ to render them robust and reliable by using related procedures of internal and external validation.

Internal validation addresses the issues of screening out device probes that do not indicate footfall, and the further screening of device probes to ‘fingerprint’ the effects of MAC randomization.
It is important to note that the filtering process work based solely on the information present in the probe requests and their temporal distribution.
This ensures that although the mobile devices were uniquely identified, there was no further personal data generated by linking the probe requests to the users of the mobile devices.
This method essentially gave us a way to estimate the footfall in real-time without identifying or tracking the mobile devices themselves.
External validation then entailed reconciling adjusted counts with the footfall observed at sample locations.
This procedure makes it possible to generalise from locations at which manual footfall surveys are conducted to all others in the system, and to develop a classification of device locations that are more or less susceptible to noise generation.

This Wi-Fi based footfall counting methodology offers a large number of applications and benefits for real time spatial analysis.
Since Wi-Fi based sensors are inexpensive and the data model is scalable, it is possible to use this methodology for a large network of sensors to gather granular data on pedestrian footfall.
A snapshot showing a week’s worth of precise footfall in area around Charring cross, London is shown in Figure \ref{main_study_counts} in order to demonstrate the potential for such a dataset.
Projects such as SmartStreetSensors \citep{cdrc2018}, may utilise this methodology to overcome the challenges introduced by the implementation of MAC address randomisation.

The vicissitudes of MAC randomisation, and the provisions of privacy legislation such as EU General Data Protection Regulations mitigate against tracking individuals across the smart city using this approach.
 This can be modelled using agent-based methods \citep{heppenstall2011}, however.
In our own research we have also begun to link store time-lagged till receipts to footfall, and have used such data to better understand the dwell times that characterise such different retail uses as stores with window displays and fast food restaurants.
 Such analysis not only provides a more nuanced picture of movement through retail areas, but also enables valorisation of micro sites within retail centres.
In the UK, for example, this is of immediate practical importance in evaluating business rates on properties, and has still wider implications for the setting of retail unit rental values.
There are obvious extensions to understanding the ebbs and flows of activities in the 24-hour smart city such as understanding urban mobility \citep{gariazzo2019} and conceptualising them with a people dimension \citep{nam2011}.

More broadly still, extensions to this strand of smart city research are likely to seek to differentiate the quality of different elements within footfall according to mission e.. travel to adjacent workplace zones, leisure, etc. and personal characteristics such as spending power. In this respect, future research may not only simulate linkage of harmonised footfall counts between sensor locations, but also link these in turn to disaggregate origin-destination matrices for bikeshare and other public transport modes. Our own investigations will consider these and other challenges to understanding the functioning of the sentient city.
